---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Post-Doctor at the [School of Computer Science, Huazhong University of Science and Technology](https://cs.hust.edu.cn), in the [HUST Media Lab](http://media.hust.edu.cn), under the supervision of <a href="http://faculty.hust.edu.cn/yujunqing/zh_CN/more/370059/jsjjgd/index.htm"><font color="blue">Prof. Junqing Yu</font></a>. I am currently as an visiting scholar at the [National University of Singapore](https://www.nus.edu.sg), under the supervision of <a href="https://sites.google.com/site/sitexinchaowang"><font color="blue">Prof. Xinchao Wang</font></a>.

I major in Computer Science and my research interests lie in the areas of **computer vision**, **motion estimation**, and **social network analysis**.

News
---
* <font color="red">**2024.12**</font>, Our Two papers on Multi-Object Tracking/Anomaly Detection are accepted to **AAAI'25**.
* <font color="red">**2024.9**</font>, Our paper on Multimodal Tech is accepted to **NeurIPS'24**.
* <font color="red">**2024.7**</font>, Our paper on Point Tracking is accepted to **ACM MM'24**.

Education
---
* B.S. in [University of Electronic Science and Technology of China](https://www.en.scse.uestc.edu.cn), 2012~2016
* M.S. in [Huazhong University of Science and Technology](https://cs.hust.edu.cn), 2016~2019
* Ph.D in [Huazhong University of Science and Technology](https://cs.hust.edu.cn), 2019~2023

Award and Service
---
* ACM Outstanding Student
* Outstanding Doctoral Scholarship
* Conference PC/Reviewers : CVPR23/24/25, ICCV23, ECCV24, AAAI24/25, NIPS24, ICLR25, ACM MM24, IJCAI24
* Journal Reviewers : TIP, TCSVT, TMM, KBS, SIGPRO

Publications
---

<table style="border-collapse:collapse; border:none">
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/OFTrack.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="">Temporal Coherent Object Flow for Multi-Object Tracking</a>
          <br>
          <strong>Zikai Song</strong>, Run Luo, Lintao Ma, Ying Tang, Yi-Ping Phoebe Chen, Junqing Yu, Wei Yang*
          <br>
          <em>AAAI</em>,2025
          <br>
          <a href="">paper</a>
          /
          <a href="">Code</a>
          <p></p>
          <p>
            We propose a section-based multi-object tracking approach that integrates a temporal coherent Object Flow Tracker, capable of achieving simultaneous multi-frame tracking by treating multiple consecutive frames as the basic processing unit, denoted as a “section”.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/zhouhangaaai24.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="">Video Anomaly Detection with Motion and Appearance Guided Patch Diffusion Model</a>
          <br>
          Hang Zhou, Cai Jiale, Yuteng Ye, Yonghui Feng, Chenxing Gao, Junqing Yu, <strong>Zikai Song*</strong>, Wei Yang
          <br>
          <em>AAAI</em>,2025
          <br>
          <a href="">paper</a>
          /
          <a href="">Code</a>
          <p></p>
          <p>
            We introduce innovative motion and appearance conditions that are seamlessly integrated into our patch diffusion model.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/couplemamba.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/pdf/2405.18014">Coupled Mamba: Enhanced Multimodal Fusion with Coupled State Space Model</a>
          <br>
          Wenbing Li, Hang Zhou, Junqing Yu, <strong>Zikai Song*</strong>, Wei Yang*
          <br>
          <em>NeurIPS</em>,2024
          <br>
          <a href="https://arxiv.org/pdf/2405.18014">paper</a>
          /
          <a href="https://github.com/hustcselwb/coupled-mamba">Code</a>
          <p></p>
          <p>
            We propose the Coupled SSM model, for coupling state chains of multiple modalities while maintaining independence of intra-modality state processes.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/ALTrack.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://www.arxiv.org/abs/2407.20730">Autogenic Language Embedding for Coherent Point Tracking</a>
          <br>
          <strong>Zikai Song</strong>, Ying Tang, Run Luo, Lintao Ma, Junqing Yu, Yi-Ping Phoebe Chen, Wei Yang*
          <br>
          <em>ACM MM</em>,2024
          <br>
          <a href="https://www.arxiv.org/abs/2407.20730">paper</a>
          <p></p>
          <p>
            We introduce a novel approach leveraging language embeddings to enhance the coherence of frame-wise visual features related to the same object.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/ICME24.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://ieeexplore.ieee.org/abstract/document/10687920">Agnostic Feature Compression with Semantic Guided Channel Importance Analysis</a>
          <br>
          Ying Tang, Wei Yang, Junqing Yu, <strong>Zikai Song*</strong>
          <br>
          <em>ICME</em>,2024
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/10687920">paper</a>
          <p></p>
          <p>
            We can apply compression operation to a deeper degree for less irrelevant parts to achieve a high compression rate, while preserving the performance by applying a lower compression ratio to the more important parts.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/amd.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/abs/2312.12763">AMD: Anatomical Motion Diffusion with Interpretable Motion Decomposition and Fusion</a>
          <br>
          Beibei Jing, Youjia Zhang, <strong>Zikai Song</strong>, Junqing Yu, Wei Yang*
          <br>
          <em>AAAI</em>,2024
          <br>
          <a href="https://arxiv.org/abs/2312.12763">arXiv</a>
          <p></p>
          <p>
            We propose the Adaptable Motion Diffusion (AMD) model, which leverages a Large Language Model (LLM) to parse the input text into a sequence of concise and interpretable anatomical scripts that correspond to the target motion.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/pt2i.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/abs/2309.09466">Progressive Text-to-Image Diffusion with Soft Latent Direction</a>
          <br>
          Yuteng Ye, Jiale Cai, Hang Zhou, Guanwen Li, Youjia Zhang, <strong>Zikai Song</strong>, Chenxing Gao, Junqing Yu, Wei Yang*
          <br>
          <em>AAAI</em>,2024
          <br>
          <a href="https://arxiv.org/abs/2309.09466">arXiv</a>
          /
          <a href="https://github.com/babahui/Progressive-Text-to-Image">Code</a>
          <p></p>
          <p>
            We propose to harness the capabilities of a Large Language Model (LLM) to decompose text descriptions into coherent directives adhering to stringent formats and progressively generate the target image.
          </p>
        </td>
    </tr>
  <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/difftrack.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/abs/2308.09905">DiffusionTrack: Diffusion Model For Multi-Object Tracking</a>
          <br>
          Run Luo, <strong>Zikai Song*</strong>, Lintao Ma, Jinlin Wei, Wei Yang, Min Yang*
          <br>
          <em>AAAI</em>,2024
          <br>
          <a href="https://arxiv.org/abs/2308.09905">arXiv</a>
          /
          <a href="https://github.com/RainBowLuoCS/DiffusionTrack">Code</a>
          <p></p>
          <p>
            We formulates object detection and association jointly as a consistent denoising diffusion process from paired noise boxes to paired ground-truth boxes.
          </p>
        </td>
    </tr>
    <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/cttrack.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/abs/2301.10938">Compact Transformer Tracker with Correlative Masked Modeling</a>
          <br>
          <strong>Zikai Song</strong>, Run Luo, Junqing Yu*, Yi-Ping Phoebe Chen, Wei Yang*
          <br>
          <em>AAAI</em>,2023
          <font color="tomato">
            <strong>(Oral Presentation)</strong>
          </font>
          <br>
          <a href="https://arxiv.org/abs/2301.10938">arXiv</a>
          /
          <a href="https://github.com/HUSTDML/CTTrack">Code</a>
          <p></p>
          <p>
            We demonstrate the basic vision transformer (ViT) architecture is sufficient for visual tracking with correlative masked modeling for information aggregation enhancement.
          </p>
        </td>
    </tr>
    <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/cswintt.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://arxiv.org/abs/2205.03806">Transformer Tracking with Cyclic Shifting Window Attention</a>
          <br>
          <strong>Zikai Song</strong>, Junqing Yu*, Yi-Ping Phoebe Chen, Wei Yang
          <br>
          <em>CVPR</em>, 2022
          <br>
          <a href="https://arxiv.org/abs/2205.03806">arXiv</a>
          /
          <a href="https://github.com/SkyeSong38/CSWinTT">Code</a>
          <p></p>
          <p>
            CSWinTT is a new transformer architecture with multi-scale cyclic shifting window attention for visual object tracking, elevating the attention from pixel to window level.
          </p>
        </td>
    </tr>
   <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/ICMR21.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://dl.acm.org/doi/abs/10.1145/3460426.3463629">Distractor-Aware Tracker with a Domain-Special Optimized Benchmark for Soccer Player Tracking</a>
          <br>
          <strong>Zikai Song</strong>, Zhiwen Wan, Wei Yuan, Ying Tang, Junqing Yu, Yi-Ping Phoebe Chen
          <br>
          <em>ICMR</em>, 2021
          <br>
          <a href="http://media.hust.edu.cn/dataset.htm">Project Page</a>
          /
          <a href="https://dl.acm.org/doi/abs/10.1145/3460426.3463629">Paper</a>
          <p></p>
          <p>
            We proposed a distractor-aware player tracking algorithm and a high-quality benchmark for soccer play tracking, deal with occlusion and similar distractors in soccer scenes.
          </p>
        </td>
    </tr>
   <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/MMM20.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://dl.acm.org/doi/abs/10.1145/3460426.3463629">Fine-Grain Level Sports Video Search Engine</a>
          <br>
          <strong>Zikai Song</strong>, Junqing Yu, Hengyou Cai, Yangliu Hu, Yi-Ping Phoebe Chen
          <br>
          <em>MultiMedia Modeling</em>, 2020
          <br>
          <a href="https://link.springer.com/chapter/10.1007/978-3-030-37731-1_42">Paper</a>
          <p></p>
          <p>
            We designed and developed a sports video search engine based on distributed architecture, aimimng to provide content-based video analysis and retrieval services
          </p>
        </td>
    </tr>
   <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/SSET.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://www.researchgate.net/profile/Zikai-Song-2/publication/343520973_SSET_a_dataset_for_shot_segmentation_event_detection_player_tracking_in_soccer_videos/links/627778df2f9ccf58eb3703ec/SSET-a-dataset-for-shot-segmentation-event-detection-player-tracking-in-soccer-videos.pdf">SSET: a dataset for shot segmentation, event detection, player tracking in soccer videos</a>
          <br>
          Na Feng, <strong>Zikai Song</strong>, Junqing Yu, Yi-Ping Phoebe Chen, Yizhu Zhao, Yunfeng He, Tao Guan
          <br>
          <em>Multimedia Tools and Applications</em>, 2020
          <br>
          <a href="http://media.hust.edu.cn/dataset.htm">Project Page</a>
          /
          <a href="https://www.researchgate.net/profile/Zikai-Song-2/publication/343520973_SSET_a_dataset_for_shot_segmentation_event_detection_player_tracking_in_soccer_videos/links/627778df2f9ccf58eb3703ec/SSET-a-dataset-for-shot-segmentation-event-detection-player-tracking-in-soccer-videos.pdf">Paper</a>
          <p></p>
          <p>
            We construct a soccer dataset named Soccer Dataset for Shot, Event, and Tracking, to meet the research needs of shot segmentation, event detection and player tracking
          </p>
        </td>
    </tr>
   <tr>
        <td varlign="middle" width="25%" style="border:none"> <img src="https://skyesong38.github.io/images/MIPR.png" /> </td>
        <td varlign="middle" width="75%" style="border:none">
          <a href="https://www.researchgate.net/profile/Zikai-Song-2/publication/326047906_Comprehensive_Dataset_of_Broadcast_Soccer_Videos/links/627779b1b1ad9f66c8ab509d/Comprehensive-Dataset-of-Broadcast-Soccer-Videos.pdf">Comprehensive dataset of broadcast soccer videos</a>
          <br>
          Junqing Yu, Aiping Lei, <strong>Zikai Song</strong>, Tingting Wang, Hengyou Cai, Na Feng
          <br>
          <em>MIPR</em>, 2018
          <br>
          <a href="http://media.hust.edu.cn/dataset.htm">Project Page</a>
          /
          <a href="https://www.researchgate.net/profile/Zikai-Song-2/publication/326047906_Comprehensive_Dataset_of_Broadcast_Soccer_Videos/links/627779b1b1ad9f66c8ab509d/Comprehensive-Dataset-of-Broadcast-Soccer-Videos.pdf">Paper</a>
          <p></p>
          <p>
            We focus on broadcast soccer videos and present a comprehensive dataset for analysis, including shot boundaries, event annotations, and bounding boxes.
          </p>
        </td>
    </tr>
</table>

Project
---
* 2023 入选国家资助博士后计划
* 2024 主持中国博士后科学基金面上项目
* 2025 主持国家自然青年科学基金
* 2025 主持湖北省博新计划项目
